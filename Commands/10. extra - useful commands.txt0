ssh localhost
/usr/local/hadoop/sbin/start-dfs.sh
/usr/local/hadoop/sbin/start-yarn.sh


/usr/local/hadoop/sbin/start-dfs.sh
/usr/local/hadoop/sbin/start-yarn.sh

hadoop fs -mkdir /spark-logs
/usr/local/spark/sbin/start-history-server.sh

spark-submit --class "cs523.SparkWC.LetterCountOfWords" --master local SparkWC.jar /user/bb/input/Lab9/lettercount /user/bb/output/Lab9/lettercount 50


/usr/local/hbase/bin/start-hbase.sh 

sudo nano ~/.profile
. ~/.profile

hbase shell


//kafka 

/usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties
/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties


/usr/local/kafka/bin/zookeeper-server-stop.sh /usr/local/kafka/config/zookeeper.properties
/usr/local/kafka/bin/kafka-server-stop.sh /usr/local/kafka/config/server.properties


/usr/local/kafka$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic streams-plaintext-input

/usr/local/kafka$ bin/kafka-run-class.sh org.apache.kafka.streams.examples.wordcount.WordCountDemo

/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
>     --topic streams-wordcount-output \
>     --from-beginning \
>     --formatter kafka.tools.DefaultMessageFormatter \
>     --property print.key=true \
>     --property print.value=true \
>     --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer \


versions:
spark 2.3.0 - 2.1.0
hadoop - 3.0.0
hbase - 1.2.6
kafka - 1.0.1
Scala 2.12

scala build tool 1.1.1

/usr/local/zeppelin/bin/zeppelin-daemon.sh start
bin/zeppelin-daemon.sh stop

lsof -i :8000
ps -fp 1289
kill -9 1289

spark-submit --class "edu.mum.bdt.BDTwitrendConsumer" --master local[2] BDTwitrendConsumer.jar localhost:9092 topic-bdtwitrend


spark-submit --class "edu.mum.bdt.java.BDTwitrendProducer" --master local[2] BDTwitrendProducer.jar 4dItFxuN84A2tRu8lsFZxkxQb 1z3EhIOEhq3kNhbBR7jM439qqMDxZX0QY1RE9u2XUo3TC7otI5 1104333505-p1hkk15wYzKmK4SHlfMIwrQXOceBKuVgAKm3h6z  prCMYT4O3nbEjZNw4yFo5fYwWzdyG3NwwoASC13Apw5yD topic-bdtwitrend trump machine leaning AI deep leaning


zeppelin
hbase dependencies
/usr/local/hbase/lib/hbase-client-1.2.6.jar	
/usr/local/hbase/lib/hbase-protocol-1.2.6.jar	
/usr/local/hbase/lib/hbase-common-1.2.6.jar

spark dependencies

/usr/local/hbase/lib/hbase-client-1.2.6.jar	
/usr/local/hbase/lib/hbase-common-1.2.6.jar	
/usr/local/hbase/lib/hbase-protocol-1.2.6.jar	
/usr/local/hbase/lib/hbase-server-1.2.6.jar	
/usr/local/hbase/lib/metrics-core-2.2.0.jar	
/usr/local/hbase/lib/shc-core-1.1.2-2.2-s_2.11-SNAPSHOT.jar	
org.apache.spark:spark-streaming-kafka-0-10_2.11:2.1.0	
org.apache.kafka:kafka-clients:0.10.1.1	
org.apache.kafka:kafka_2.11:0.10.1.1



sudo netstat -plnt | grep 'java'
 ps -aux | grep 'java' | less



//hbase shell

truncate 'tblTweet'
truncate 'tblHashTag'

create 'tblTweet', 'Tweet', 'Geo'
create 'tblHashTag', 'Info'


ps -aux | grep 'zeppelin-spark'


// con expression
0/10 * * * * ? - every 10 seconds



/usr/local/thirdpartylibs/spark-highcharts-0.6.5.jar
/usr/local/thirdpartylibs/lift-json_2.11-2.6.3.jar
