{"paragraphs":[{"text":"%md\n## Welcome to BDTwitrend.\n#### This is the class project of Big Data Technology course, you can run the code yourself. (Shift-Enter to Run)\n##### Batjargal Bayarsaikhan (Alex) - 986264\n##### March 14-19 2018","user":"anonymous","dateUpdated":"2018-03-16T01:53:23-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","tableHide":false,"editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Welcome to BDTwitrend.</h2>\n<h4>This is the class project of Big Data Technology course, you can run the code yourself. (Shift-Enter to Run)</h4>\n<h5>Batjargal Bayarsaikhan (Alex) - 986264</h5>\n<h5>March 14-19 2018</h5>\n</div>"}]},"apps":[],"jobName":"paragraph_1521168859685_-851216986","id":"20180315-215419_1197411295","dateCreated":"2018-03-15T21:54:19-0500","dateStarted":"2018-03-16T01:53:23-0500","dateFinished":"2018-03-16T01:53:28-0500","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:101"},{"title":"Load data into table (SparkSQL/DataFrames)","text":"%spark\n\nimport org.apache.spark.sql.execution.datasources.hbase._\nimport org.apache.spark.sql._\n\ndef catalog = s\"\"\"{\n  |\"table\":{\"namespace\":\"default\", \"name\":\"Streaming_wordcount\"},\n  |\"rowkey\":\"key\",\n  |\"columns\":{\n    |\"col0\":{\"cf\":\"rowkey\", \"col\":\"key\", \"type\":\"string\"},\n    |\"col1\":{\"cf\":\"Word_count\", \"col\":\"Occurances\", \"type\":\"string\"}\n  |}\n|}\"\"\".stripMargin\n\ndef withCatalog(cat: String): DataFrame = {\n  sqlContext\n  .read\n  .options(Map(HBaseTableCatalog.tableCatalog->cat))\n  .format(\"org.apache.spark.sql.execution.datasources.hbase\")\n  .load()\n}\n\nval df = withCatalog(catalog)\nval s = df.select(\"col0\", \"col1\")\ndf.registerTempTable(\"tblWordCount\")\nsqlContext.sql(\"select count(col1) from tblWordCount\").show\n","user":"anonymous","dateUpdated":"2018-03-16T02:52:19-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":false,"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1521173966188_1155987074","id":"20180315-231926_1177327453","dateCreated":"2018-03-15T23:19:26-0500","dateStarted":"2018-03-16T02:52:19-0500","dateFinished":"2018-03-16T02:52:25-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:102","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.execution.datasources.hbase._\nimport org.apache.spark.sql._\ncatalog: String\nwithCatalog: (cat: String)org.apache.spark.sql.DataFrame\ndf: org.apache.spark.sql.DataFrame = [col0: string, col1: string]\ns: org.apache.spark.sql.DataFrame = [col0: string, col1: string]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n+-----------+\n|count(col1)|\n+-----------+\n|         27|\n+-----------+\n\n"}]}},{"text":"%sql\n\nselect col0, sum(col1) from tblWordCount group by col0","user":"anonymous","dateUpdated":"2018-03-16T02:55:52-0500","config":{"colWidth":6,"enabled":true,"results":{"0":{"graph":{"mode":"pieChart","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"col0\tsum(CAST(col1 AS DOUBLE))\n(hhhhhh,1)\t1.0\n(yarn,1)\t2.0\n(yanaa,1)\t1.0\n(world.,1)\t1.0\n(bla,1)\t1.0\n(How,1)\t1.0\n(ooo,3)\t1.0\n(from,1)\t1.0\n(line.,1)\t1.0\n(you?,1)\t1.0\n(hhl,3)\t1.0\n(beautiful,1)\t1.0\n(lklk,3)\t1.0\n(gggggggggh,1)\t1.0\n(bla,3)\t1.0\n(bla,4)\t1.0\n(hello,1)\t4.0\n(ggggggggg,1)\t1.0\n(are,1)\t1.0\n(google,3)\t1.0\n(hwllo,1)\t1.0\n(,3)\t1.0\n(am,1)\t1.0\n(world,1)\t4.0\n(command,1)\t1.0\n(world,,1)\t1.0\n(i,1)\t1.0\n"}]},"apps":[],"jobName":"paragraph_1521174300512_-1311516536","id":"20180315-232500_1915977820","dateCreated":"2018-03-15T23:25:00-0500","dateStarted":"2018-03-16T02:55:18-0500","dateFinished":"2018-03-16T02:55:23-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:103"},{"text":"%sql\n\nselect col0, col1 from tblWordCount","user":"anonymous","dateUpdated":"2018-03-16T02:54:26-0500","config":{"colWidth":6,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false},"helium":{}}},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"col0\tcol1\n(,3)\t1\n(How,1)\t1\n(am,1)\t1\n(are,1)\t1\n(beautiful,1)\t1\n(bla,1)\t1\n(bla,3)\t1\n(bla,4)\t1\n(command,1)\t1\n(from,1)\t1\n(ggggggggg,1)\t1\n(gggggggggh,1)\t1\n(google,3)\t1\n(hello,1)\t4\n(hhhhhh,1)\t1\n(hhl,3)\t1\n(hwllo,1)\t1\n(i,1)\t1\n(line.,1)\t1\n(lklk,3)\t1\n(ooo,3)\t1\n(world,,1)\t1\n(world,1)\t4\n(world.,1)\t1\n(yanaa,1)\t1\n(yarn,1)\t2\n(you?,1)\t1\n"}]},"apps":[],"jobName":"paragraph_1521175399522_741110100","id":"20180315-234319_781167094","dateCreated":"2018-03-15T23:43:19-0500","dateStarted":"2018-03-16T02:53:08-0500","dateFinished":"2018-03-16T02:53:08-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:104"},{"text":"%spark\n\nimport …   \n\n\nval endpointUrl = \"https://kinesis.us-east-1.amazonaws.com\"\nval credentials = new DefaultAWSCredentialsProviderChain().getCredentials()\n    require(credentials != null,\n      \"No AWS credentials found. Please specify credentials using one of the methods specified \" +\n        \"in http://docs.aws.amazon.com/AWSSdkDocsJava/latest/DeveloperGuide/credentials.html\")\n    val kinesisClient = new AmazonKinesisClient(credentials)\n    kinesisClient.setEndpoint(\"https://kinesis.us-east-1.amazonaws.com\")\n    val numShards = kinesisClient.describeStream(\"spark-demo\").getStreamDescription().getShards().size\n\nval numStreams = numShards\n\n//Setting batch interval to 5 seconds\nval batchInterval = Seconds(5)\nval kinesisCheckpointInterval = batchInterval\nval regionName = RegionUtils.getRegionByEndpoint(endpointUrl).getName()\n\n \nval ssc = new StreamingContext(sc, batchInterval)\n\n // Create the DStreams\n    val kinesisStreams = (0 until numStreams).map { i =>\n      KinesisUtils.createStream(ssc, \"app-spark-demo\", \"spark-demo\", endpointUrl, regionName,InitialPositionInStream.LATEST, kinesisCheckpointInterval, StorageLevel.MEMORY_AND_DISK_2)\n    }\n\n\n// Union all the streams\nval unionStreams = ssc.union(kinesisStreams)\n\n//Schema of the incoming data on the stream\nval schemaString = \"device_id,temperature,timestamp\"\n\n//Parse the data in DStreams\nval tableSchema = StructType( schemaString.split(\",\").map(fieldName => StructField(fieldName, StringType, true)))\n\n//Processing each RDD and storing it in temporary table\n unionStreams.foreachRDD ((rdd: RDD[Array[Byte]], time: Time) => {\n  val rowRDD = rdd.map(w => Row.fromSeq(new String(w).split(\",\")))\n  val wordsDF = sqlContext.createDataFrame(rowRDD,tableSchema)\n  wordsDF.registerTempTable(\"realTimeTable\")\n})\n\n","user":"anonymous","dateUpdated":"2018-03-16T03:05:00-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1521187476093_-1259947698","id":"20180316-030436_113209093","dateCreated":"2018-03-16T03:04:36-0500","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1789"},{"text":"%hbase\nhelp\n","user":"anonymous","dateUpdated":"2018-03-16T02:53:26-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1521184000456_646705863","id":"20180316-020640_805817092","dateCreated":"2018-03-16T02:06:40-0500","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:105"}],"name":"BDTwitrend","id":"2DBDF3FF5","angularObjects":{"2DANCNB5W:shared_process":[],"2DASSW9U5:shared_process":[],"2D7UT1Q6X:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}